\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{tikz}
\usepackage{float}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{caption}
\usepackage{subcaption}

% Define TikZ libraries for diagrams
\usetikzlibrary{arrows.meta, positioning, shapes, shadows, trees}

% Setup hyperref
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

% Setup code listings
\lstset{
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    commentstyle=\color{green!60!black},
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    numbersep=5pt,
    frame=single,
    framesep=5pt,
    rulecolor=\color{black!30},
    tabsize=4,
}

% Setup page geometry
\geometry{margin=1in}

\title{\LARGE \textbf{ΛCDM Cosmological Parameter Inference Project Documentation}}
\author{PHYS212 Final Project}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
    This document provides comprehensive documentation for the ΛCDM Cosmological Parameter Inference project. It outlines the purpose and functionality of each file in the repository, explains the project architecture through visual diagrams, and describes the relationships between different components. This documentation facilitates understanding of the codebase and supports future extension or modification of the project.
\end{abstract}

\tableofcontents

\newpage

\section{Project Overview}

The ΛCDM Cosmological Parameter Inference project implements a complete pipeline for inferring cosmological parameters from Planck CMB data using the ΛCDM model. The project employs Markov Chain Monte Carlo (MCMC) methods including both standard sampling and temperature annealing techniques to determine parameter constraints.

\subsection{Key Features}

\begin{itemize}
    \item Implementation of the ΛCDM cosmological model using CAMB
    \item Bayesian inference framework for parameter estimation
    \item Both standard MCMC and temperature annealing methods
    \item Analysis tools for parameter constraints and visualization
    \item HPC integration for execution on computing clusters
    \item Checkpoint/restart capabilities for long-running jobs
\end{itemize}

\subsection{Project Architecture}

The project is organized into several functional components:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    module/.style={draw, rounded corners, fill=blue!10, minimum width=3cm, minimum height=1cm, align=center, drop shadow},
    arrow/.style={thick, ->, >=stealth},
]
    % Core modules
    \node[module] (camb) {CAMB Interface};
    \node[module, below=of camb] (theory) {Theoretical Model};
    \node[module, below=of theory] (data) {Data Handling};
    \node[module, right=2cm of camb] (mcmc) {MCMC Framework};
    \node[module, below=of mcmc] (analysis) {Analysis Tools};
    \node[module, below=of analysis] (hpc) {HPC Support};

    % Arrows connecting modules
    \draw[arrow] (camb) -- (theory);
    \draw[arrow] (theory) -- (data);
    \draw[arrow] (data) -- (mcmc);
    \draw[arrow] (mcmc) -- (analysis);
    \draw[arrow] (mcmc) -- (hpc);
    \draw[arrow] (hpc) to[bend left] (analysis);
    
    % Module contents
    \node[below=0.15cm of camb, font=\footnotesize] {CAMB.py};
    \node[below=0.15cm of theory, font=\footnotesize] {theoretical\_lcdm.py, cosmology\_model.py};
    \node[below=0.15cm of data, font=\footnotesize] {data\_loader.py, likelihood.py};
    \node[below=0.15cm of mcmc, font=\footnotesize] {mcmc\_run.py, modified\_mcmc.py, priors.py};
    \node[below=0.15cm of analysis, font=\footnotesize] {analyze\_standard\_chains.py, analyze\_annealing\_chains.py};
    \node[below=0.15cm of hpc, font=\footnotesize] {restart\_continue\_chains.py, run scripts};
\end{tikzpicture}
\caption{High-level architecture of the ΛCDM Parameter Inference project}
\label{fig:architecture}
\end{figure}

\newpage

\subsection{Data Flow}

The following diagram illustrates the data flow through the system:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.5cm and 2.5cm,
    block/.style={rectangle, draw, fill=blue!10, rounded corners, minimum height=1cm, minimum width=3cm, align=center},
    data/.style={cylinder, draw, shape aspect=0.3, fill=green!10, minimum height=0.8cm, minimum width=2cm, align=center},
    connector/.style={->, thick},
]
    % Data nodes
    \node[data] (planck) {Planck FITS Data};
    \node[data, right=of planck] (param) {Parameter Space};
    
    % Processing blocks
    \node[block, below=of planck] (dataload) {Data Loader};
    \node[block, below=of param] (camb) {CAMB \& Cosmology};
    \node[block, below=of dataload] (likelihood) {Likelihood Function};
    \node[block, below=of camb] (mcmc) {MCMC Sampler};
    \node[block, below right=of likelihood] (posterior) {Posterior Distribution};
    \node[block, below=of posterior] (analysis) {Analysis \& Visualization};
    
    % Result node
    \node[data, below=of analysis] (results) {Parameter Constraints};
    
    % Connect everything
    \draw[connector] (planck) -- (dataload);
    \draw[connector] (param) -- (camb);
    \draw[connector] (dataload) -- (likelihood);
    \draw[connector] (camb) -- (likelihood);
    \draw[connector] (likelihood) -- (mcmc);
    \draw[connector] (mcmc) -- (posterior);
    \draw[connector] (posterior) -- (analysis);
    \draw[connector] (analysis) -- (results);
    
    % Additional connections
    \draw[connector] (param) to[bend left] (mcmc);
    \draw[connector, dashed] (mcmc) to[bend right] (camb);
    
    % Labels
    \node[font=\footnotesize, text width=3cm, align=center, below right=0.2cm and 0cm of dataload] {ell, dl, sigma};
    \node[font=\footnotesize, text width=3cm, align=center, below left=0.2cm and 0cm of camb] {theory spectrum};
    \node[font=\footnotesize, text width=3cm, align=center, left=0.2cm of posterior] {MCMC chains};
\end{tikzpicture}
\caption{Data flow diagram of the ΛCDM Parameter Inference pipeline}
\label{fig:data-flow}
\end{figure}

\newpage

\section{Repository Structure}

This section outlines the current structure of the repository, organized by category.

\subsection{Core Files}

\begin{itemize}
    \item \textbf{Cosmological Model Implementation}
    \begin{itemize}
        \item \texttt{CAMB.py}
        \item \texttt{theoretical\_lcdm.py}
        \item \texttt{cosmology\_model.py}
        \item \texttt{parameters.py}
        \item \texttt{priors.py}
    \end{itemize}
    
    \item \textbf{Data Handling}
    \begin{itemize}
        \item \texttt{data\_loader.py}
        \item \texttt{likelihood.py}
    \end{itemize}
    
    \item \textbf{MCMC Implementation}
    \begin{itemize}
        \item \texttt{mcmc\_run.py} (Standard MCMC)
        \item \texttt{modified\_mcmc.py} (Temperature Annealing MCMC)
        \item \texttt{restart\_continue\_chains.py} (Chain Continuation Utilities)
    \end{itemize}
    
    \item \textbf{Analysis Scripts}
    \begin{itemize}
        \item \texttt{analyze\_standard\_chains.py}
        \item \texttt{analyze\_annealing\_chains.py}
        \item \texttt{analyze\_final\_steps.py}
        \item \texttt{compare\_annealing\_runs.py}
        \item \texttt{compare\_with\_planck.py}
        \item \texttt{visualize\_constraints.py}
        \item \texttt{visualize\_model\_fits.py}
    \end{itemize}
    
    \item \textbf{Run Scripts}
    \begin{itemize}
        \item \texttt{analyze\_results.sh}
        \item \texttt{run\_annealing\_analysis\_engaging.sh}
        \item \texttt{run\_combined\_analysis.sh}
    \end{itemize}
\end{itemize}

\subsection{Raw Data and Results Directories}

\begin{itemize}
    \item \textbf{Standard MCMC}
    \begin{itemize}
        \item \texttt{standard\_mcmc\_raw\_data\_and\_results/} - Contains raw chains and output from standard MCMC runs
        \begin{itemize}
            \item \texttt{chain\_*\_full.npz} - Standard MCMC chain files (4 chains)
            \item \texttt{corner\_plot.png} - Corner plot of parameter distributions
            \item \texttt{parameter\_constraints.csv} - Parameter constraints from standard MCMC
            \item \texttt{posterior\_samples\_lambdaCDM.npy} - Posterior samples
            \item \texttt{trace\_plots.png} - Trace plots for convergence diagnostics
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Annealing MCMC}
    \begin{itemize}
        \item \texttt{annealing\_raw\_data/} - Contains raw data from two annealing MCMC runs
        \begin{itemize}
            \item \texttt{first\_run/mcmc\_results\_annealing\_20250422\_170412.zip} - First annealing run results
            \item \texttt{second\_run/mcmc\_results\_merged.zip} - Second annealing run results with merged chains
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Analysis Results Directories}

\begin{itemize}
    \item \texttt{annealing\_analysis/} - Results from analyzing the annealing MCMC runs
    \begin{itemize}
        \item \texttt{annealing\_corner\_plot.png} - Corner plot for annealing chains
        \item \texttt{annealing\_parameter\_constraints.csv} - Parameter constraints
        \item \texttt{annealing\_posterior\_samples.npy} - Posterior samples
        \item \texttt{annealing\_temperature\_schedule.png} - Temperature schedule visualization
        \item \texttt{annealing\_trace\_plots.png} - Trace plots for annealing chains
    \end{itemize}
    
    \item \texttt{annealing\_analysis\_final\_steps\_only/} - Analysis focused on final steps of annealing chains
    \begin{itemize}
        \item \texttt{final\_steps\_corner\_plot.png} - Corner plot for final steps
        \item \texttt{final\_steps\_parameter\_constraints.csv} - Parameter constraints from final steps
        \item \texttt{final\_steps\_summary.md} - Summary of final steps analysis
        \item \texttt{final\_steps\_trace\_plots.png} - Trace plots for final steps
        \item \texttt{gelman\_rubin\_final\_steps.txt} - Convergence statistics for final steps
    \end{itemize}
    
    \item \texttt{annealing\_chains\_comparison/} - Comparison between different annealing runs
    \begin{itemize}
        \item \texttt{comparison\_summary.txt} - Summary of comparison
        \item \texttt{corner\_plot\_mcmc\_results\_annealing\_20250422\_170412.png} - Corner plot for first run
        \item \texttt{corner\_plot\_mcmc\_results\_merged.png} - Corner plot for merged results
        \item \texttt{gelman\_rubin\_stats.txt} - Convergence statistics
        \item \texttt{parameter\_comparison.png} - Parameter comparison visualization
    \end{itemize}
    
    \item \texttt{standard\_chains\_analysis/} - Results from analyzing standard MCMC runs
    \begin{itemize}
        \item \texttt{standard\_chains\_summary.md} - Summary of standard MCMC analysis
        \item \texttt{standard\_corner\_plot.png} - Corner plot for standard chains
        \item \texttt{standard\_gelman\_rubin.txt} - Convergence statistics
        \item \texttt{standard\_parameter\_constraints.csv} - Parameter constraints
        \item \texttt{standard\_trace\_plots.png} - Trace plots for standard chains
        \item \texttt{standard\_vs\_annealing.csv} - Comparison data
        \item \texttt{standard\_vs\_annealing\_comparison.md} - Detailed comparison
        \item \texttt{standard\_vs\_annealing\_comparison.png} - Comparison visualization
    \end{itemize}
\end{itemize}

\subsection{Documentation}

\begin{itemize}
    \item \texttt{README.md} - Main project documentation
    \item \texttt{README\_MCMC.md} - Detailed documentation on the MCMC implementation
    \item \texttt{FULL\_RESTART\_GUIDE.md} - Guide for restarting interrupted MCMC runs
    \item \texttt{PROJECT\_SUMMARY.md} - Brief summary of the project structure
    \item \texttt{complete\_project\_report.tex} - This comprehensive documentation
    \item \texttt{requirements.txt} - Python package dependencies
\end{itemize}

\section{File Descriptions}

This section provides detailed descriptions of each file in the repository, organized by functional category.

\subsection{Core Cosmological Model}

\begin{table}[H]
\centering
\begin{tabular}{p{4cm}p{11cm}}
\toprule
\textbf{File} & \textbf{Description} \\
\midrule
\texttt{CAMB.py} & Provides an interface to the CAMB (Code for Anisotropies in the Microwave Background) package. It configures and runs CAMB with specified cosmological parameters to generate theoretical CMB power spectra. \\
\addlinespace
\texttt{theoretical\_lcdm.py} & Implements the ΛCDM cosmological model. It handles the transformation between cosmological parameters and CAMB parameters, and defines the theoretical model used for comparison with observational data. \\
\addlinespace
\texttt{cosmology\_model.py} & Contains the core cosmological model calculations. It handles parameter mappings, units, and conversions, and provides utility functions for cosmological calculations. \\
\bottomrule
\end{tabular}
\caption{Core Cosmological Model Files}
\label{tab:cosmology-files}
\end{table}

\subsection{Data Handling and Likelihood}

\begin{table}[H]
\centering
\begin{tabular}{p{4cm}p{11cm}}
\toprule
\textbf{File} & \textbf{Description} \\
\midrule
\texttt{data\_loader.py} & Handles loading and processing of Planck CMB data. It provides functions to extract data from the FITS file, apply necessary transformations, and prepare it for comparison with theoretical predictions. \\
\addlinespace
\texttt{likelihood.py} & Implements the likelihood function that compares theoretical predictions with observational data. It calculates the log-likelihood of parameter sets given the Planck data, forming the basis for the Bayesian inference. \\
\addlinespace
\texttt{parameters.py} & Defines the cosmological parameters and their fiducial values. It specifies the parameter ranges, default values, and transformations used throughout the project. \\
\addlinespace
\texttt{priors.py} & Implements the prior distributions for cosmological parameters. It defines the log-prior and log-posterior functions used in the MCMC sampling. \\
\bottomrule
\end{tabular}
\caption{Data Handling and Likelihood Files}
\label{tab:data-likelihood-files}
\end{table}

\subsection{MCMC Implementation}

\begin{table}[H]
\centering
\begin{tabular}{p{4cm}p{11cm}}
\toprule
\textbf{File} & \textbf{Description} \\
\midrule
\texttt{mcmc\_run.py} & Implements the standard Metropolis-Hastings MCMC algorithm. It provides functions for running MCMC chains, creating checkpoints, and analyzing results. This is the primary file for running standard MCMC parameter inference. \\
\addlinespace
\texttt{modified\_mcmc.py} & Implements the temperature annealing MCMC method. It extends the standard MCMC with a temperature schedule that improves parameter space exploration. This file provides enhanced sampling capabilities for more robust parameter constraints. \\
\addlinespace
\texttt{restart\_continue\_chains.py} & Provides tools for continuing interrupted MCMC runs from checkpoints. It includes functions to find, load, and merge checkpoint files, continue chains from their last state, and combine results for analysis. \\
\bottomrule
\end{tabular}
\caption{MCMC Implementation Files}
\label{tab:mcmc-files}
\end{table}

\subsection{Analysis and Visualization}

\begin{table}[H]
\centering
\begin{tabular}{p{4cm}p{11cm}}
\toprule
\textbf{File} & \textbf{Description} \\
\midrule
\texttt{analyze\_standard\_chains.py} & Script for analyzing standard MCMC chains. It processes chain files, calculates parameter constraints, and generates visualizations. \\
\addlinespace
\texttt{analyze\_annealing\_chains.py} & Script for analyzing temperature annealing MCMC chains. It processes annealing chain files, calculates parameter constraints, and produces specialized visualizations that include temperature schedule information. \\
\addlinespace
\texttt{analyze\_final\_steps.py} & Script focused on analyzing the final steps of annealing chains, which correspond to the samples from the target distribution after the temperature has reached its final value. \\
\addlinespace
\texttt{compare\_annealing\_runs.py} & Script for comparing results from different annealing runs. It facilitates comparison of different temperature schedules and their impact on parameter constraints. \\
\addlinespace
\texttt{compare\_with\_planck.py} & Script for comparing inferred parameters with published Planck values. It generates comparison plots and calculates differences between the project's results and official Planck constraints. \\
\addlinespace
\texttt{visualize\_constraints.py} & Generates visualizations of parameter constraints from MCMC chains. It creates corner plots, marginalized posteriors, and credible interval visualizations. \\
\addlinespace
\texttt{visualize\_model\_fits.py} & Creates visualizations comparing theoretical model predictions with observational data. It plots power spectra, residuals, and parameter sensitivity analyses. \\
\bottomrule
\end{tabular}
\caption{Analysis and Visualization Files}
\label{tab:analysis-files}
\end{table}

\newpage

\section{Data Directories}

This section details the content and purpose of each data directory in the repository.

\subsection{Raw Data Directories}

\begin{table}[H]
\centering
\begin{tabular}{p{5cm}p{10cm}}
\toprule
\textbf{Directory} & \textbf{Description} \\
\midrule
\texttt{standard\_mcmc\_raw\_data\_and\_results/} & Contains the raw MCMC chains from standard Metropolis-Hastings runs. Includes chain files (\texttt{chain\_*\_full.npz}), posterior samples, and visualization outputs such as corner plots and trace plots. This directory contains the complete output from the standard MCMC inference pipeline. \\
\addlinespace
\texttt{annealing\_raw\_data/first\_run/} & Contains the first temperature annealing MCMC run results as a zip file. This run uses an exponential temperature schedule as documented in the implementation. The file contains chain data, log-posterior values, and temperature schedules. \\
\addlinespace
\texttt{annealing\_raw\_data/second\_run/} & Contains the second temperature annealing MCMC run results as a zip file, named \texttt{mcmc\_results\_merged.zip}. This file includes potentially merged chain data from continued runs using the chain continuation methodology. \\
\bottomrule
\end{tabular}
\caption{Raw Data Directories}
\label{tab:raw-data-dirs}
\end{table}

\subsection{Analysis Results Directories}

\begin{table}[H]
\centering
\begin{tabular}{p{5cm}p{10cm}}
\toprule
\textbf{Directory} & \textbf{Description} \\
\midrule
\texttt{annealing\_analysis/} & Contains analysis results from the annealing MCMC runs, including corner plots, trace plots, temperature schedule visualization, parameter constraints, and posterior samples. This directory provides a comprehensive analysis of the temperature annealing MCMC performance. \\
\addlinespace
\texttt{annealing\_analysis\_final\_steps\_only/} & Contains analysis focused specifically on the final steps of annealing chains, which represent samples from the target distribution after the temperature has reached its final value. Includes parameter constraints, visualizations, Gelman-Rubin convergence statistics, and a detailed summary of the findings. \\
\addlinespace
\texttt{annealing\_chains\_comparison/} & Contains comparison results between different annealing runs, including corner plots, parameter comparisons, Gelman-Rubin convergence statistics, and a summary of the comparison findings. This directory allows for evaluation of different temperature annealing strategies. \\
\addlinespace
\texttt{standard\_chains\_analysis/} & Contains analysis results from the standard MCMC runs, including corner plots, trace plots, parameter constraints, Gelman-Rubin statistics, and importantly, comparisons with annealing results. This directory facilitates direct comparison between standard and annealing MCMC approaches. \\
\bottomrule
\end{tabular}
\caption{Analysis Results Directories}
\label{tab:analysis-dirs}
\end{table}

\newpage

\section{MCMC Implementation Details}

This section provides a detailed look at the MCMC implementation in the project, including standard and temperature annealing methods.

\subsection{Standard MCMC Algorithm}

The standard MCMC implementation follows the Metropolis-Hastings algorithm:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.2cm,
    block/.style={rectangle, draw, fill=blue!10, rounded corners, minimum height=0.8cm, minimum width=3.5cm, align=center},
    decision/.style={diamond, draw, fill=yellow!20, aspect=2, minimum width=3cm, align=center},
    arrow/.style={thick, ->, >=stealth},
]
    % Algorithm steps
    \node[block] (init) {Initialize parameters $\theta_0$};
    \node[block, below=of init] (prior) {Calculate initial log-posterior $L_0$};
    \node[block, below=of prior] (loop) {For step $i = 1$ to $N$:};
    \node[block, below=of loop] (propose) {Propose new parameters $\theta'$};
    \node[block, below=of propose] (calc) {Calculate new log-posterior $L'$};
    \node[decision, below=of calc] (accept) {Accept new state?\\$U(0,1) < \exp(L' - L_i)$};
    \node[block, below left=of accept] (update_yes) {$\theta_{i+1} = \theta'$\\$L_{i+1} = L'$};
    \node[block, below right=of accept] (update_no) {$\theta_{i+1} = \theta_i$\\$L_{i+1} = L_i$};
    \node[block, below=1.8cm of accept] (checkpoint) {Create checkpoint if needed};
    
    % Connect everything
    \draw[arrow] (init) -- (prior);
    \draw[arrow] (prior) -- (loop);
    \draw[arrow] (loop) -- (propose);
    \draw[arrow] (propose) -- (calc);
    \draw[arrow] (calc) -- (accept);
    \draw[arrow] (accept) -- node[left] {Yes} (update_yes);
    \draw[arrow] (accept) -- node[right] {No} (update_no);
    \draw[arrow] (update_yes) |- (checkpoint);
    \draw[arrow] (update_no) |- (checkpoint);
    \draw[arrow] (checkpoint) -| ++(-4.5,0) |- (propose);
    
    % Add loop back indicator
    \draw[arrow, dashed] (checkpoint) -- ++(0,-0.5) -| ++(-5,0) |- (loop);
\end{tikzpicture}
\caption{Standard Metropolis-Hastings MCMC algorithm implementation}
\label{fig:standard-mcmc}
\end{figure}

\subsection{Temperature Annealing MCMC}

The temperature annealing MCMC extends the standard algorithm with a temperature schedule:

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.2cm,
    block/.style={rectangle, draw, fill=blue!10, rounded corners, minimum height=0.8cm, minimum width=4cm, align=center},
    decision/.style={diamond, draw, fill=yellow!20, aspect=2, minimum width=3cm, align=center},
    temp/.style={rectangle, draw, fill=red!10, rounded corners, minimum height=0.8cm, minimum width=4cm, align=center},
    arrow/.style={thick, ->, >=stealth},
]
    % Algorithm steps
    \node[block] (init) {Initialize parameters $\theta_0$};
    \node[temp, below=of init] (temp_init) {Set initial temperature $T_0 = T_{initial}$};
    \node[block, below=of temp_init] (prior) {Calculate initial log-posterior $L_0$};
    \node[block, below=of prior] (loop) {For step $i = 1$ to $N$:};
    \node[temp, below=of loop] (update_temp) {Update temperature $T_i$ based on schedule};
    \node[block, below=of update_temp] (propose) {Propose new parameters $\theta'$};
    \node[block, below=of propose] (calc) {Calculate new log-posterior $L'$};
    \node[decision, below=of calc] (accept) {Accept new state?\\$U(0,1) < \exp((L' - L_i)/T_i)$};
    \node[block, below left=of accept] (update_yes) {$\theta_{i+1} = \theta'$\\$L_{i+1} = L'$};
    \node[block, below right=of accept] (update_no) {$\theta_{i+1} = \theta_i$\\$L_{i+1} = L_i$};
    \node[block, below=1.8cm of accept] (checkpoint) {Create checkpoint with temperature};
    
    % Connect everything
    \draw[arrow] (init) -- (temp_init);
    \draw[arrow] (temp_init) -- (prior);
    \draw[arrow] (prior) -- (loop);
    \draw[arrow] (loop) -- (update_temp);
    \draw[arrow] (update_temp) -- (propose);
    \draw[arrow] (propose) -- (calc);
    \draw[arrow] (calc) -- (accept);
    \draw[arrow] (accept) -- node[left] {Yes} (update_yes);
    \draw[arrow] (accept) -- node[right] {No} (update_no);
    \draw[arrow] (update_yes) |- (checkpoint);
    \draw[arrow] (update_no) |- (checkpoint);
    \draw[arrow] (checkpoint) -| ++(-5,0) |- (loop);
\end{tikzpicture}
\caption{Temperature annealing MCMC algorithm implementation}
\label{fig:annealing-mcmc}
\end{figure}

\subsection{Temperature Schedules}

The project implements three temperature schedules for annealing:

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=12cm, height=8cm,
    xlabel={MCMC Step Progress (\%)},
    ylabel={Temperature},
    xmin=0, xmax=100,
    ymin=0.8, ymax=5.2,
    legend pos=north east,
    grid=both,
    y label style={at={(axis description cs:-0.1,.5)},anchor=south},
]

% Exponential schedule
\addplot[thick, blue, domain=0:100] {5*exp(x*ln(1/5)/100)};

% Linear schedule
\addplot[thick, red, domain=0:100] {5 - 4*x/100};

% Sigmoid schedule
\addplot[thick, green!60!black, domain=0:100] {5 - 4*(1/(1 + exp(-0.1*(x-50))))};

\legend{Exponential, Linear, Sigmoid}
\end{axis}
\end{tikzpicture}
\caption{Temperature schedules for annealing MCMC}
\label{fig:temp-schedules}
\end{figure}

\newpage

\section{Chain Continuation and Merging}

A key feature of this project is the ability to continue MCMC chains that were interrupted and merge the results for analysis.

\subsection{Chain Continuation Process}

The chain continuation process implemented in \texttt{restart\_continue\_chains.py} follows these steps:

\begin{enumerate}
    \item \textbf{Checkpoint Detection}: Automatically searches for the latest checkpoint files for each chain.
    \item \textbf{Parameter State Recovery}: Extracts the final parameter state, log-posterior value, and in annealing runs, the current temperature from the checkpoint.
    \item \textbf{Continuation Parameters}: Calculates the number of remaining steps and appropriate temperature for restart (in annealing runs).
    \item \textbf{Chain Continuation}: Continues the MCMC chain from the exact state where it was interrupted.
    \item \textbf{Chain Merging}: Combines the original chain segment with the continued segment into a coherent MCMC chain.
\end{enumerate}

\subsection{Temperature Schedule Handling}

For annealing runs, the temperature schedule must be handled carefully when continuing chains:

\begin{itemize}
    \item \textbf{Temperature Calculation}: The temperature for restart is calculated based on the progress of the chain and the selected temperature schedule.
    \item \textbf{Schedule Consistency}: The same temperature schedule type (exponential, linear, or sigmoid) must be used for continuation.
    \item \textbf{Temperature Tracking}: The temperature values for each step are tracked and stored along with the chain data.
\end{itemize}

\section{Analysis and Visualization Methods}

This section describes the analysis and visualization methods used in the project.

\subsection{Parameter Constraint Analysis}

The project implements several methods for analyzing parameter constraints:

\begin{itemize}
    \item \textbf{Posterior Distributions}: Calculates marginalized posterior distributions for each parameter using kernel density estimation.
    
    \item \textbf{Credible Intervals}: Computes 68\% and 95\% credible intervals for each parameter from MCMC chains.
    
    \item \textbf{Convergence Diagnostics}: Implements Gelman-Rubin statistics to assess convergence of multiple chains.
    
    \item \textbf{Corner Plots}: Generates corner plots showing parameter correlations and marginalized distributions.
    
    \item \textbf{Trace Plots}: Creates trace plots to visualize chain mixing and convergence over time.
    
    \item \textbf{Temperature Schedule Visualization}: For annealing runs, creates plots of the temperature schedule over time.
\end{itemize}

\subsection{Comparison Methods}

The project includes several methods for comparing different MCMC approaches:

\begin{itemize}
    \item \textbf{Standard vs. Annealing Comparison}: Compares parameter constraints between standard MCMC and temperature annealing methods.
    
    \item \textbf{Annealing Run Comparison}: Compares results from different annealing runs, potentially with different temperature schedules.
    
    \item \textbf{Final Steps Analysis}: Analyzes only the final steps of annealing chains, when the temperature has reached its final value.
    
    \item \textbf{Planck Comparison}: Compares inferred parameters with published Planck constraints.
\end{itemize}

\section{Project Extensions and Future Work}

This section discusses potential extensions and future work for the project.

\subsection{Potential Extensions}

\begin{itemize}
    \item \textbf{Extended Cosmological Models}: The project could be extended to support beyond-ΛCDM models, such as models with varying dark energy equation of state, massive neutrinos, or primordial non-Gaussianity.
    
    \item \textbf{Additional Datasets}: Support for additional cosmological datasets could be added, such as BAO, SNe Ia, or lensing data, allowing for joint constraints.
    
    \item \textbf{Advanced MCMC Methods}: Implementation of more advanced MCMC methods, such as Hamiltonian Monte Carlo or Nested Sampling, could improve sampling efficiency.
    
    \item \textbf{Distributed Computing}: Enhanced support for distributed computing could allow for even larger MCMC runs across multiple computing nodes.
    
    \item \textbf{Interactive Visualization}: Development of interactive visualization tools could facilitate exploration of the parameter posterior distributions.
\end{itemize}

\subsection{Recommended Next Steps}

\begin{enumerate}
    \item \textbf{Code Optimization}: Profiling and optimizing the most computationally intensive parts of the code.
    
    \item \textbf{Documentation Enhancement}: Expanding code documentation and user guides.
    
    \item \textbf{Unit Testing}: Implementing comprehensive unit tests for all components.
    
    \item \textbf{Containerization}: Creating Docker containers to simplify deployment and ensure reproducibility.
    
    \item \textbf{Parameter Sensitivity Analysis}: Conducting a thorough sensitivity analysis of the MCMC results to prior choices and data processing decisions.
\end{enumerate}

\section{Conclusion}

The ΛCDM Cosmological Parameter Inference project provides a comprehensive framework for inferring cosmological parameters from Planck CMB data. By implementing both standard and temperature annealing MCMC methods, it enables robust parameter constraints with improved exploration of parameter space.

The modular design, extensive documentation, and HPC integration make this project a versatile tool for cosmological research. The checkpoint and restart capabilities ensure that long-running jobs can be continued efficiently, even on time-limited computing resources.

This project demonstrates the advantages of temperature annealing MCMC for cosmological parameter inference, particularly for exploring complicated posterior distributions with degeneracies and multiple modes.

\end{document}